{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926bae46",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf2cddc-fdb8-4efb-acce-14bd17afd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import convnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae636ae-24d1-4523-9997-696731318a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from imutils import paths\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4f0a2",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8238055-08bf-44e1-8f3b-98e7768f1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 256\n",
    "IMAGE_SIZE = 224\n",
    "BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/convnext-tf/keras-applications/convnext/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f52f8a4-be56-4a32-843c-18639f010384",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS = {\n",
    "    \"tiny\": {\n",
    "        \"depths\": [3, 3, 9, 3],\n",
    "        \"projection_dims\": [96, 192, 384, 768],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "    \"small\": {\n",
    "        \"depths\": [3, 3, 27, 3],\n",
    "        \"projection_dims\": [96, 192, 384, 768],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "    \"base\": {\n",
    "        \"depths\": [3, 3, 27, 3],\n",
    "        \"projection_dims\": [128, 256, 512, 1024],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "    \"large\": {\n",
    "        \"depths\": [3, 3, 27, 3],\n",
    "        \"projection_dims\": [192, 384, 768, 1536],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "    \"xlarge\": {\n",
    "        \"depths\": [3, 3, 27, 3],\n",
    "        \"projection_dims\": [256, 512, 1024, 2048],\n",
    "        \"default_size\": 224,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115b327f-b60b-459f-a51d-45d2c6b09565",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_HASHES = {\n",
    "  \"tiny\":\n",
    "    (\"594e0f8c77df6cdf30d07e92f19d530921a53ff8301edd130c1bb9ad3dd6f25b\",\n",
    "      \"278a5149e8c6e26f001051db5a8398f40f233994af2921a072bdca54389a9048\"),\n",
    "  \"small\":\n",
    "    (\"8f26cee79fea02bbbbdc721e7dd5d416562106b7768ec37459850c7b23f26cb2\",\n",
    "      \"b0700a330b2e8bfa6862b61d333d3d8860e566ce2f9395a2165e506935bba547\"),\n",
    "  \"base\":\n",
    "    (\"2c08893b86245f4fc1d80f584faeb7431b23e895b03f71fc3d943a3489b60089\",\n",
    "      \"a3d12bf8938796ca00721db89cb9e5a1af77f847401348adef16fab3611233d3\"),\n",
    "  \"large\":\n",
    "    (\"f17f979cc7cd23906a88f490ff1249d2b0dedc44a601f5700a0873afc1b0ad02\",\n",
    "      \"74ff1e5f6eee45c62194aaee4a3347d5e2cf574caccad414b2b117b3ad110b32\"),\n",
    "  \"xlarge\":\n",
    "    (\"784b923c2db18fec883093b265c2a44c4fc401425f206a3ca036015290f401e8\",\n",
    "      \"ba28c90cf6a4c64acfe0ca3af3ad920652c50f24668a3aaaf245a1c47e7bfe6f\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edcf20",
   "metadata": {},
   "source": [
    "## Set up ImageNet-1k labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334993ee-0d91-4572-9721-03e67af28cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    "    imagenet_labels = json.load(read_file)\n",
    "\n",
    "MAPPING_DICT = {}\n",
    "LABEL_NAMES = {}\n",
    "for label_id in list(imagenet_labels.keys()):\n",
    "    MAPPING_DICT[imagenet_labels[label_id][0]] = int(label_id)\n",
    "    LABEL_NAMES[int(label_id)] = imagenet_labels[label_id][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ad5447-3e28-4c86-941f-f64b45be603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['val/n03000134/ILSVRC2012_val_00009432.JPEG',\n",
       "  'val/n03000134/ILSVRC2012_val_00018410.JPEG',\n",
       "  'val/n03000134/ILSVRC2012_val_00043280.JPEG',\n",
       "  'val/n03000134/ILSVRC2012_val_00041208.JPEG',\n",
       "  'val/n03000134/ILSVRC2012_val_00014205.JPEG'],\n",
       " [489, 489, 489, 489, 489])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_val_paths = list(paths.list_images(\"val\"))\n",
    "all_val_labels = [MAPPING_DICT[x.split(\"/\")[1]] for x in all_val_paths]\n",
    "\n",
    "all_val_paths[:5], all_val_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1124817d",
   "metadata": {},
   "source": [
    "## Preprocessing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4f03d8-25d1-4660-9858-1b197425d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model already has a normalization layer inside.\n",
    "def load_and_prepare(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, (256, 256), method=\"bicubic\")\n",
    "    image = tf.image.central_crop(image, 0.875)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d33240",
   "metadata": {},
   "source": [
    "## Prepare `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3518397-2ab0-4d79-adea-ae5f1cb66add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 09:05:46.601711: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 09:05:52.695772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38414 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((all_val_paths, all_val_labels))\n",
    "dataset = dataset.map(load_and_prepare, num_parallel_calls=AUTO).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(AUTO)\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42076a",
   "metadata": {},
   "source": [
    "## Initialize models and run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f503707-6e94-433b-802a-e56dc51bcae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_tiny.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 594e0f8c77df6cdf30d07e92f19d530921a53ff8301edd130c1bb9ad3dd6f25b so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_tiny.h5\n",
      "114581504/114579080 [==============================] - 1s 0us/step\n",
      "114589696/114579080 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize 0.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 09:06:04.717526: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-05-02 09:06:10.428064: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 89s 391ms/step - loss: 0.0000e+00 - accuracy: 0.8131\n",
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_small.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 8f26cee79fea02bbbbdc721e7dd5d416562106b7768ec37459850c7b23f26cb2 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_small.h5\n",
      "201310208/201308664 [==============================] - 1s 0us/step\n",
      "201318400/201308664 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize 0.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "196/196 [==============================] - 89s 428ms/step - loss: 0.0000e+00 - accuracy: 0.8239\n",
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_base.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 2c08893b86245f4fc1d80f584faeb7431b23e895b03f71fc3d943a3489b60089 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_base.h5\n",
      "354779136/354773392 [==============================] - 2s 0us/step\n",
      "354787328/354773392 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize 0.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "196/196 [==============================] - 117s 567ms/step - loss: 0.0000e+00 - accuracy: 0.8536\n",
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_large.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of f17f979cc7cd23906a88f490ff1249d2b0dedc44a601f5700a0873afc1b0ad02 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_large.h5\n",
      "791486464/791481848 [==============================] - 4s 0us/step\n",
      "791494656/791481848 [==============================] - 4s 0us/step\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize 0.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "196/196 [==============================] - 174s 858ms/step - loss: 0.0000e+00 - accuracy: 0.8636\n",
      "Fetching checkpoint from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_xlarge.h5.\n",
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 784b923c2db18fec883093b265c2a44c4fc401425f206a3ca036015290f401e8 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/convnext-tf/keras-applications/convnext/convnext_xlarge.h5\n",
      "1401208832/1401200848 [==============================] - 6s 0us/step\n",
      "1401217024/1401200848 [==============================] - 6s 0us/step\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize 0.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "196/196 [==============================] - 237s 1s/step - loss: 0.0000e+00 - accuracy: 0.8673\n"
     ]
    }
   ],
   "source": [
    "for model_name in MODEL_CONFIGS:\n",
    "    config = MODEL_CONFIGS.get(model_name)\n",
    "    model = convnext.ConvNeXt(\n",
    "        **config,\n",
    "        include_top=True\n",
    "    )\n",
    "    checkpoint_path = os.path.join(BASE_WEIGHTS_PATH, f\"convnext_{model_name}.h5\")\n",
    "    print(f\"Fetching checkpoint from {checkpoint_path}.\")\n",
    "    \n",
    "    file_hash = WEIGHTS_HASHES.get(model_name)[0]\n",
    "    weights_path = keras.utils.get_file(\n",
    "        f\"convnext_{model_name}.h5\",\n",
    "        checkpoint_path,\n",
    "        cache_subdir=\"models\",\n",
    "        file_hash=file_hash\n",
    "    )\n",
    "    model.load_weights(weights_path)\n",
    "    model.compile(metrics=[\"accuracy\"])\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs_{model_name}\")\n",
    "    \n",
    "    _, accuracy = model.evaluate(dataset, callbacks=[tb_callback])\n",
    "    accuracy = round(accuracy * 100, 4)\n",
    "    print(f\"{model_name}: {accuracy}%.\", file=open(f\"{model_name}.txt\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
