{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/keras-convnext-conversion/blob/master/in1k-eval/convert_and_calculate_hashes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIYdn1woOS1n",
        "outputId": "21c5512d-feb2-4fca-b5d7-4063868f40a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 7.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ml_collections timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -q https://github.com/sayakpaul/keras-convnext-conversion"
      ],
      "metadata": {
        "id": "7QOvcCw4M9EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd keras-convnext-conversion\n",
        "!mkdir keras-applications\n",
        "!mkdir keras-applications/convnext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19AvNPG3NCMa",
        "outputId": "70ae0aaf-efbb-4cf2-c449-0d1f891c5ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keras-convnext-conversion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_all.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1erh-ezpNFwe",
        "outputId": "5a412ff8-3dcb-4875-ad38-150c3128243c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting 224x224 resolution ImageNet-1k models.\n",
            "\r  0% 0/5 [00:00<?, ?it/s]Converting convnext_tiny with classification top.\n",
            "Model: convnext_tiny\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny_1k_224_ema.pth\n",
            "100% 109M/109M [00:03<00:00, 32.3MB/s]\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:29:36.175814: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_tiny.h5...\n",
            "Converting convnext_tiny without classification top.\n",
            "Model: convnext_tiny\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:29:45.159857: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_tiny_notop.h5...\n",
            " 20% 1/5 [00:22<01:28, 22.17s/it]Converting convnext_small with classification top.\n",
            "Model: convnext_small\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth\" to /root/.cache/torch/hub/checkpoints/convnext_small_1k_224_ema.pth\n",
            "100% 192M/192M [00:04<00:00, 45.8MB/s]\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:29:59.144521: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_small.h5...\n",
            "Converting convnext_small without classification top.\n",
            "Model: convnext_small\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_small_1k_224_ema.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:30:11.143724: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_small_notop.h5...\n",
            " 40% 2/5 [00:50<01:17, 25.91s/it]Converting convnext_base with classification top.\n",
            "Model: convnext_base\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_224.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_224.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base_22k_1k_224.pth\n",
            "100% 338M/338M [00:08<00:00, 41.1MB/s]\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:30:32.791815: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_base.h5...\n",
            "Converting convnext_base without classification top.\n",
            "Model: convnext_base\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_224.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:30:46.659438: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_base_notop.h5...\n",
            " 60% 3/5 [01:27<01:01, 30.78s/it]Converting convnext_large with classification top.\n",
            "Model: convnext_large\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_224.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_224.pth\" to /root/.cache/torch/hub/checkpoints/convnext_large_22k_1k_224.pth\n",
            "100% 755M/755M [00:21<00:00, 36.4MB/s]\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:31:24.840881: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_large.h5...\n",
            "Converting convnext_large without classification top.\n",
            "Model: convnext_large\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_224.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:31:45.065854: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_large_notop.h5...\n",
            " 80% 4/5 [02:29<00:43, 43.11s/it]Converting convnext_xlarge with classification top.\n",
            "Model: convnext_xlarge\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_224_ema.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_224_ema.pth\" to /root/.cache/torch/hub/checkpoints/convnext_xlarge_22k_1k_224_ema.pth\n",
            "100% 1.30G/1.30G [00:37<00:00, 37.6MB/s]\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:32:45.889887: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-04-17 06:32:47.253273: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n",
            "2022-04-17 06:32:47.276689: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n",
            "2022-04-17 06:32:47.280372: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n",
            "2022-04-17 06:32:47.306281: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n",
            "2022-04-17 06:32:47.328398: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 16777216 exceeds 10% of free system memory.\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_xlarge.h5...\n",
            "Converting convnext_xlarge without classification top.\n",
            "Model: convnext_xlarge\n",
            "Image resolution: 224\n",
            "Dataset: imagenet-1k\n",
            "Checkpoint URL: https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_224_ema.pth\n",
            "Instantiating PyTorch model and populating weights...\n",
            "Instantiating TensorFlow model...\n",
            "2022-04-17 06:33:16.412340: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-04-17 06:33:22.283078: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 33554432 exceeds 10% of free system memory.\n",
            "2022-04-17 06:33:22.328530: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 33554432 exceeds 10% of free system memory.\n",
            "2022-04-17 06:33:22.335571: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 33554432 exceeds 10% of free system memory.\n",
            "2022-04-17 06:33:22.383832: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
            "2022-04-17 06:33:22.483031: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
            "TensorFlow model instantiated, populating pretrained weights...\n",
            "Weight population successful, serializing TensorFlow model...\n",
            "TensorFlow model serialized to: keras-applications/convnext/convnext_xlarge_notop.h5...\n",
            "100% 5/5 [04:07<00:00, 49.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "AZw2jolfOdTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMIlXS_aOsOe",
        "outputId": "d39bfe5a-4fd6-4d04-ef32-12884ff0986d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keras-convnext-conversion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil -m cp -r keras-applications gs://convnext-tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrDT30IMOs3x",
        "outputId": "40874b68-fa8a-4860-ff0f-8ea0f9c30270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://keras-applications/convnext/convnext_tiny_notop.h5 [Content-Type=application/octet-stream]...\n",
            "/ [0/10 files][    0.0 B/  5.3 GiB]   0% Done                                   \rCopying file://keras-applications/convnext/convnext_tiny.h5 [Content-Type=application/octet-stream]...\n",
            "/ [0/10 files][    0.0 B/  5.3 GiB]   0% Done                                   \rCopying file://keras-applications/convnext/convnext_xlarge_notop.h5 [Content-Type=application/octet-stream]...\n",
            "/ [0/10 files][    0.0 B/  5.3 GiB]   0% Done                                   \rCopying file://keras-applications/convnext/convnext_large_notop.h5 [Content-Type=application/octet-stream]...\n",
            "/ [0/10 files][    0.0 B/  5.3 GiB]   0% Done                                   \rCopying file://keras-applications/convnext/convnext_base_notop.h5 [Content-Type=application/octet-stream]...\n",
            "/ [0/10 files][    0.0 B/  5.3 GiB]   0% Done                                   \rCopying file://keras-applications/convnext/convnext_xlarge.h5 [Content-Type=application/octet-stream]...\n",
            "/ [0/10 files][    0.0 B/  5.3 GiB]   0% Done                                   \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file://keras-applications/convnext/convnext_small.h5 [Content-Type=application/octet-stream]...\n",
            "/ [0/10 files][    0.0 B/  5.3 GiB]   0% Done                                   \rCopying file://keras-applications/convnext/convnext_small_notop.h5 [Content-Type=application/octet-stream]...\n",
            "/ [0/10 files][    0.0 B/  5.3 GiB]   0% Done                                   \rCopying file://keras-applications/convnext/convnext_large.h5 [Content-Type=application/octet-stream]...\n",
            "Copying file://keras-applications/convnext/convnext_base.h5 [Content-Type=application/octet-stream]...\n",
            "\\\n",
            "Operation completed over 10 objects/5.3 GiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import glob \n",
        "\n",
        "all_weights = glob.glob(\"/content/keras-convnext-conversion/keras-applications/convnext/*.h5\")\n",
        "all_weights = sorted(all_weights)\n",
        "all_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeVj9Ww-PQ4x",
        "outputId": "f5342fa3-9b12-436b-91e6-fb15e4f734cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/keras-convnext-conversion/keras-applications/convnext/convnext_base.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_base_notop.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_large.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_large_notop.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_small.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_small_notop.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_tiny.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_tiny_notop.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_xlarge.h5',\n",
              " '/content/keras-convnext-conversion/keras-applications/convnext/convnext_xlarge_notop.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_hashes = {}\n",
        "\n",
        "for weight_file in all_weights:\n",
        "    architecture = weight_file.split(\"/\")[-1].split(\".\")[0]\n",
        "    if \"notop\" in architecture:\n",
        "        architecture = architecture.replace(\"_notop\", \"\")\n",
        "\n",
        "    # https://www.quickprogrammingtips.com/python/how-to-calculate-sha256-hash-of-a-file-in-python.html\n",
        "    with open(weight_file,\"rb\") as f:\n",
        "        bytes = f.read() # read entire file as bytes\n",
        "        readable_hash = hashlib.sha256(bytes).hexdigest()\n",
        "\n",
        "        if architecture not in weight_hashes:\n",
        "            weight_hashes.update({architecture: [readable_hash]})\n",
        "        else:\n",
        "            weight_hashes.get(architecture).append(readable_hash)"
      ],
      "metadata": {
        "id": "Tmov-NgePmdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_hashes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AHiR1rxRR3d",
        "outputId": "75bda71e-cc45-4364-e024-a1ee541294bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'convnext_base': ['d30e0c509f4e1abe2784d33765d4391ce8fbff259b0bd79f4a63684b20db87d2',\n",
              "  '736f7a96cd933ee568611e29f334737fb9aebaaea021ea7adfe4d2f5cbb4a9aa'],\n",
              " 'convnext_large': ['8a304c66deb782b0d59837bc13127068901adaaa280cfac604d3341aaf44b2cf',\n",
              "  'b02b623b3c28586423e6be4aa214e2f5619280b97b4ef6b35ffb686e83235f01'],\n",
              " 'convnext_small': ['f964ea5cd5618a1e64902a74ca5ccff3797a4fa5dba11a14f2c4d1a562b72f08',\n",
              "  'fd8f0ac74faa4e364d7cb5b2d32af9ae35b54ce5e80525b5beb7b7571320065a'],\n",
              " 'convnext_tiny': ['dec324e40ebe943afc7b75b72484646eeb092c04bb079df35911d7080364f9a8',\n",
              "  '4d4f0e079db2cc0e627b55f7d0d76c367145d14f2c90674415373457cd822346'],\n",
              " 'convnext_xlarge': ['da65d1294d386c71aebd81bc2520b8d42f7f60eee4414806c60730cd63eb15cb',\n",
              "  '2bfbf5f0c2b3f004f1c32e9a76661e11a9ac49014ed2a68a49ecd0cd6c88d377']}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}